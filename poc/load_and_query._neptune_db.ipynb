{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f27b8d0-7f1a-414b-8a19-931c02043282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gremlinpython\n",
      "  Downloading gremlinpython-3.7.4-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: nest-asyncio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gremlinpython) (1.6.0)\n",
      "Collecting aiohttp<4.0.0,>=3.8.0 (from gremlinpython)\n",
      "  Downloading aiohttp-3.13.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting aenum<4.0.0,>=1.4.5 (from gremlinpython)\n",
      "  Downloading aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting isodate<1.0.0,>=0.6.0 (from gremlinpython)\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.3 (from gremlinpython)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.0->gremlinpython)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.0->gremlinpython)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->gremlinpython) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.0->gremlinpython)\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.0->gremlinpython)\n",
      "  Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.0->gremlinpython)\n",
      "  Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.0->gremlinpython)\n",
      "  Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp<4.0.0,>=3.8.0->gremlinpython) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.8.0->gremlinpython) (3.10)\n",
      "Downloading gremlinpython-3.7.4-py3-none-any.whl (78 kB)\n",
      "Downloading aenum-3.1.16-py3-none-any.whl (165 kB)\n",
      "Downloading aiohttp-3.13.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n",
      "Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n",
      "Installing collected packages: aenum, propcache, multidict, isodate, frozenlist, async-timeout, aiohappyeyeballs, yarl, aiosignal, aiohttp, gremlinpython\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [gremlinpython]0m [aiohttp]t]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aenum-3.1.16 aiohappyeyeballs-2.6.1 aiohttp-3.13.0 aiosignal-1.4.0 async-timeout-4.0.3 frozenlist-1.8.0 gremlinpython-3.7.4 isodate-0.7.2 multidict-6.7.0 propcache-0.4.1 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gremlinpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a12f7-c9a8-455e-b9a3-e26b48858761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to migrate to gremlin query\n",
    "def compute_shortest_path(\n",
    "    edges: List[Tuple[str, str, float, int]],\n",
    "    source: str,\n",
    "    sink: str,\n",
    "    cost_scale: int = 1,\n",
    "    undirected: bool = False,\n",
    ") -> Tuple[List[str], float]:\n",
    "    if SimpleMinCostFlow is None:\n",
    "        raise ShortestPathError(\n",
    "            \"ortools not available or incompatible. Install with 'pip install ortools'.\"\n",
    "        )\n",
    "\n",
    "    if source == sink:\n",
    "        return [source], 0.0\n",
    "\n",
    "    if cost_scale <= 0:\n",
    "        raise ShortestPathError(\"cost_scale must be a positive integer\")\n",
    "\n",
    "    # Map node names to integer ids and preserve reverse mapping for output\n",
    "    node_name_to_id: Dict[str, int] = {}\n",
    "    node_id_to_name: Dict[int, str] = {}\n",
    "\n",
    "    def get_node_id(name: str) -> int:\n",
    "        if name not in node_name_to_id:\n",
    "            new_id = len(node_name_to_id)\n",
    "            node_name_to_id[name] = new_id\n",
    "            node_id_to_name[new_id] = name\n",
    "        return node_name_to_id[name]\n",
    "\n",
    "    start_nodes: List[int] = []\n",
    "    end_nodes: List[int] = []\n",
    "    capacities: List[int] = []\n",
    "    unit_costs: List[int] = []\n",
    "\n",
    "    for u_name, v_name, cost_value, capacity_value in edges:\n",
    "        u_id = get_node_id(u_name)\n",
    "        v_id = get_node_id(v_name)\n",
    "\n",
    "        # Scale cost to integer for OR-Tools\n",
    "        scaled_cost = int(round(cost_value * cost_scale))\n",
    "\n",
    "        start_nodes.append(u_id)\n",
    "        end_nodes.append(v_id)\n",
    "        capacities.append(max(1, int(capacity_value)))\n",
    "        unit_costs.append(scaled_cost)\n",
    "\n",
    "        if undirected:\n",
    "            start_nodes.append(v_id)\n",
    "            end_nodes.append(u_id)\n",
    "            capacities.append(max(1, int(capacity_value)))\n",
    "            unit_costs.append(scaled_cost)\n",
    "\n",
    "    # Ensure source and sink are in the mapping even if isolated in the edge list\n",
    "    source_id = get_node_id(source)\n",
    "    sink_id = get_node_id(sink)\n",
    "\n",
    "    flow_solver = SimpleMinCostFlow()\n",
    "\n",
    "    # Compatibility helpers across pywrapgraph (CamelCase) and python (snake_case) APIs\n",
    "    def add_arc_with_capacity_and_unit_cost(tail: int, head: int, capacity: int, unit_cost: int) -> None:\n",
    "        if hasattr(flow_solver, \"AddArcWithCapacityAndUnitCost\"):\n",
    "            flow_solver.AddArcWithCapacityAndUnitCost(tail, head, capacity, unit_cost)\n",
    "        else:\n",
    "            flow_solver.add_arc_with_capacity_and_unit_cost(tail, head, capacity, unit_cost)\n",
    "\n",
    "    def set_node_supply(node_id: int, supply: int) -> None:\n",
    "        if hasattr(flow_solver, \"SetNodeSupply\"):\n",
    "            flow_solver.SetNodeSupply(node_id, supply)\n",
    "        else:\n",
    "            flow_solver.set_node_supply(node_id, supply)\n",
    "\n",
    "    def solve() -> object:\n",
    "        if hasattr(flow_solver, \"Solve\"):\n",
    "            return flow_solver.Solve()\n",
    "        return flow_solver.solve()\n",
    "\n",
    "    def num_arcs() -> int:\n",
    "        return flow_solver.NumArcs() if hasattr(flow_solver, \"NumArcs\") else flow_solver.num_arcs()\n",
    "\n",
    "    def flow(i: int) -> int:\n",
    "        return flow_solver.Flow(i) if hasattr(flow_solver, \"Flow\") else flow_solver.flow(i)\n",
    "\n",
    "    def tail(i: int) -> int:\n",
    "        return flow_solver.Tail(i) if hasattr(flow_solver, \"Tail\") else flow_solver.tail(i)\n",
    "\n",
    "    def head(i: int) -> int:\n",
    "        return flow_solver.Head(i) if hasattr(flow_solver, \"Head\") else flow_solver.head(i)\n",
    "\n",
    "    def optimal_cost() -> int:\n",
    "        return (\n",
    "            flow_solver.OptimalCost() if hasattr(flow_solver, \"OptimalCost\") else flow_solver.optimal_cost()\n",
    "        )\n",
    "\n",
    "    for i in range(len(start_nodes)):\n",
    "        add_arc_with_capacity_and_unit_cost(\n",
    "            start_nodes[i], end_nodes[i], capacities[i], unit_costs[i]\n",
    "        )\n",
    "\n",
    "    all_node_ids = list(node_id_to_name.keys())\n",
    "    for node_id in all_node_ids:\n",
    "        set_node_supply(node_id, 0)\n",
    "\n",
    "    set_node_supply(source_id, 1)\n",
    "    set_node_supply(sink_id, -1)\n",
    "\n",
    "    status = solve()\n",
    "\n",
    "    # Determine the OPTIMAL status constant in both APIs\n",
    "    optimal_status = getattr(flow_solver, \"OPTIMAL\", None)\n",
    "    if optimal_status is None and hasattr(flow_solver, \"Status\"):\n",
    "        optimal_status = flow_solver.Status.OPTIMAL\n",
    "\n",
    "    if status != optimal_status:\n",
    "        raise ShortestPathError(\n",
    "            f\"Min-cost flow did not find a solution (status={status}).\"\n",
    "        )\n",
    "\n",
    "    # Extract the unique unit-flow path from source to sink\n",
    "    next_by_node: Dict[int, int] = {}\n",
    "    for i in range(num_arcs()):\n",
    "        if flow(i) > 0:\n",
    "            t = tail(i)\n",
    "            h = head(i)\n",
    "            next_by_node[t] = h\n",
    "\n",
    "    if source_id not in next_by_node:\n",
    "        raise ShortestPathError(\"No path found carrying unit flow from source to sink\")\n",
    "\n",
    "    ordered_path_ids: List[int] = [source_id]\n",
    "    visited: set[int] = set([source_id])\n",
    "\n",
    "    while ordered_path_ids[-1] != sink_id:\n",
    "        current = ordered_path_ids[-1]\n",
    "        if current not in next_by_node:\n",
    "            raise ShortestPathError(\n",
    "                \"Disconnected flow: could not reconstruct a full path to sink\"\n",
    "            )\n",
    "        nxt = next_by_node[current]\n",
    "        if nxt in visited:\n",
    "            raise ShortestPathError(\"Cycle encountered while reconstructing path\")\n",
    "        ordered_path_ids.append(nxt)\n",
    "        visited.add(nxt)\n",
    "\n",
    "    ordered_path_names = [node_id_to_name[nid] for nid in ordered_path_ids]\n",
    "\n",
    "    total_cost_scaled = optimal_cost()\n",
    "    total_cost = float(total_cost_scaled) / float(cost_scale)\n",
    "\n",
    "    return ordered_path_names, total_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb70324b-67df-4712-9ea0-3c8e64da1a5d",
   "metadata": {},
   "source": [
    "##### Convert GR to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc557c-2cd9-43a1-9e53-ee2086041845",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/datasets/roads/\"\n",
    "in_gr_path  = data_path+\"USA-road-d.USA.gr\"\n",
    "out_csv_path = data_path+\"USA-road-d.USA.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a07155-ae33-4cb5-8872-22c1310fd2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../\"+in_gr_path,'r') as f:\n",
    "    with open(\"../\"+out_csv_path,'w') as g:\n",
    "        g.write(\"src,dest,dist\\n\")\n",
    "        for line in f:\n",
    "            if line.startswith('a '):\n",
    "                line = line.replace('a ','').replace(' ',',')\n",
    "                g.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d421d69-d885-4e06-b699-2194071c210b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c33f72b-9801-48d6-8c55-0a14e01e0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gremlinpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00abf6f0-8bd7-45a3-84d5-95b52bca4a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query Neptune using gremlin\n",
    "from gremlin_python import statics\n",
    "from gremlin_python.structure.graph import Graph\n",
    "from gremlin_python.process.graph_traversal import __\n",
    "from gremlin_python.process.strategies import *\n",
    "from gremlin_python.driver.driver_remote_connection import DriverRemoteConnection\n",
    "from gremlin_python.driver.aiohttp.transport import AiohttpTransport\n",
    "from gremlin_python.process.traversal import *\n",
    "import os\n",
    "\n",
    "port = 8182\n",
    "server = '(your server endpoint)'\n",
    "\n",
    "endpoint = f'wss://{server}:{port}/gremlin'\n",
    "\n",
    "graph=Graph()\n",
    "\n",
    "connection = DriverRemoteConnection(endpoint,'g',\n",
    "                 transport_factory=lambda:AiohttpTransport(call_from_event_loop=True))\n",
    "\n",
    "g = graph.traversal().withRemote(connection)\n",
    "\n",
    "results = (g.V().hasLabel('airport')\n",
    "                .sample(10)\n",
    "                .order()\n",
    "                .by('code')\n",
    "                .local(__.values('code','city').fold())\n",
    "                .toList())\n",
    "\n",
    "# Print the results in a tabular form with a row index\n",
    "for i,c in enumerate(results,1):\n",
    "    print(\"%3d %4s %s\" % (i,c[0],c[1]))\n",
    "\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
